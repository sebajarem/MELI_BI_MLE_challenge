{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "political-intent",
   "metadata": {},
   "source": [
    "# MercadoLibre Desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-fluid",
   "metadata": {},
   "source": [
    "## NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-people",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "competent-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "technological-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "after-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autocompleter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "driving-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = autocompleter.Autocompleter()\n",
    "\n",
    "ac.import_json('sample_conversations.json')\n",
    "\n",
    "ac.conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "novel-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Hello Werner how may I help you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Sure I can help you with that? Could you pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Let me update that information on our system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>OK Wernzio, I have updated your address to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Ok let me go ahead and request a work order fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               Text\n",
       "0      9             Hello Werner how may I help you today?\n",
       "1     11  Sure I can help you with that? Could you pleas...\n",
       "2     13       Let me update that information on our system\n",
       "3     14  OK Wernzio, I have updated your address to the...\n",
       "4     16  Ok let me go ahead and request a work order fo..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_agent = ac.conversations[ac.conversations['IsFromCustomer'] == False]['Text'].reset_index()\n",
    "text_agent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "productive-blake",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = list(text_agent['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "assured-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_juntas = '. '.join(text_agent['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "streaming-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = frases_juntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "veterinary-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "thirty-privilege",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'werner', 'how', 'may', 'i', 'help', 'you', 'today', '?', '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "organic-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams language modelling\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apart-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "model = MLE(n) # train a 3-grams model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "american-sacramento",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "medical-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 2858 items>\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, padded_sents)\n",
    "print(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "turned-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "registered-pursuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('could', 'you', 'please', 'provide', 'me', 'with', 'your', 'new', 'address', '?', '.')\n"
     ]
    }
   ],
   "source": [
    "print(model.vocab.lookup(tokenized_text[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dried-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 575505 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "naval-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['what', 'is']]['your'] # i.e. Count('your'|'what is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "noble-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'password', '.', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(num_words=5, text_seed='how may' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-edition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "artistic-mongolia",
   "metadata": {},
   "source": [
    "### Ngrams\n",
    "(Clase de la Maestria)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "civilian-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "still-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lower = text.lower()\n",
    "#text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "romance-knight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_sent = sent_tokenize(text_lower)\n",
    "#text_sent\n",
    "text_sent = [word_tokenize(s) for s in text_sent ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "premier-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train3gram(corpus):\n",
    "      # Create a placeholder for model\n",
    "      model3 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "      # Count frequency of co-occurance \n",
    "      for s in corpus:\n",
    "          for w1, w2, w3 in trigrams(s, pad_right=True, pad_left=True):\n",
    "              model3[(w1, w2)][w3] += 1\n",
    "\n",
    "      for w1_w2 in model3:\n",
    "          total_count = float(sum(model3[w1_w2].values()))\n",
    "          for w3 in model3[w1_w2]:\n",
    "              model3[w1_w2][w3] /= total_count\n",
    "\n",
    "      return model3\n",
    "\n",
    "def generateSentence(model, start):\n",
    "      # starting words\n",
    "      text = start\n",
    "      sentence_finished = False\n",
    "      \n",
    "      while not sentence_finished:\n",
    "        # select a random probability threshold  \n",
    "        r = random.random()\n",
    "        accumulator = .0\n",
    "\n",
    "        h = tuple(text[-2:])\n",
    "\n",
    "        for w in model[h].keys():\n",
    "            accumulator += model[h][w]\n",
    "            # select words that are above the probability threshold\n",
    "            if accumulator >= r:\n",
    "                text.append(w)\n",
    "                break\n",
    "\n",
    "        if text[-2:] == [None, None] or len(text) == 15:\n",
    "            sentence_finished = True\n",
    "      \n",
    "      print (' '.join([t for t in text if t]))\n",
    "        \n",
    "def generateSentence(model, start):\n",
    "      # starting words\n",
    "      text = start\n",
    "      sentence_finished = False\n",
    "      \n",
    "      while not sentence_finished:\n",
    "        h = tuple(text[-2:])\n",
    "\n",
    "        for w in model[h].keys():\n",
    "            accumulator += model[h][w]\n",
    "            # select words that are above the probability threshold\n",
    "            if accumulator >= r:\n",
    "                text.append(w)\n",
    "                break\n",
    "\n",
    "        if text[-2:] == [None, None] or len(text) == 15:\n",
    "            sentence_finished = True\n",
    "      \n",
    "      print (' '.join([t for t in text if t]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "short-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_tri = train3gram(text_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "above-excess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.37017994858611825,\n",
       " 'going': 0.06940874035989718,\n",
       " 'your': 0.506426735218509,\n",
       " 'our': 0.002570694087403599,\n",
       " 'an': 0.002570694087403599,\n",
       " 'yours': 0.002570694087403599,\n",
       " 'wrong': 0.005141388174807198,\n",
       " 'you': 0.007712082262210797,\n",
       " 'a': 0.002570694087403599,\n",
       " 'causing': 0.007712082262210797,\n",
       " 'cause': 0.002570694087403599,\n",
       " 'her': 0.002570694087403599,\n",
       " 'phone': 0.005141388174807198,\n",
       " 'email': 0.002570694087403599,\n",
       " 'cell': 0.002570694087403599,\n",
       " 'available': 0.002570694087403599,\n",
       " 'happening': 0.005141388174807198}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(m1_tri['what', 'is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "advance-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your model white or the next available appointment is scheduled\\ .\n"
     ]
    }
   ],
   "source": [
    "generateSentence(m1_tri, ['what', 'is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-abraham",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37-tf-gpu]",
   "language": "python",
   "name": "conda-env-py37-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
